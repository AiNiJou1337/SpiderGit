# 代码分析配置说明

## 📋 概述

关键词爬虫在爬取仓库后，会自动分析仓库的代码文件，提取以下信息：
- 导入的库/包（imports）
- 函数定义（functions）
- 组件定义（components）
- API端点（api_endpoints）

## ⚙️ 配置方式

### 方式1：前端界面配置（推荐）✨

在 Keywords 页面的搜索栏中：
1. 点击"高级选项"
2. 找到"代码分析数量"设置
3. 选择或输入分析数量：
   - **全部分析 (0)**：分析所有爬取的仓库
   - **分析前100个**（默认推荐）
   - **分析前50个**：快速模式
   - **不分析 (-1)**：只获取仓库元数据
   - **自定义数量**：输入任意正整数

### 方式2：环境变量配置（高级）

通过 `.env` 文件中的 `CODE_ANALYSIS_LIMIT` 环境变量控制默认行为：

| 值 | 行为 | 适用场景 |
|---|------|---------|
| `0` | **全部分析** | 小型关键词（<50个仓库），需要完整数据 |
| `100` | **分析前100个**（默认） | 平衡性能与数据完整性 |
| `50` | 分析前50个 | 快速模式 |
| `-1` | **不分析** | 只需要仓库元数据，不需要代码级别信息 |

在 `.env` 文件中添加：
```bash
# 默认分析前100个
CODE_ANALYSIS_LIMIT=100
```

## 📊 性能对比

### 示例：爬取 100 个仓库

| 配置 | 分析数量 | API调用 | 耗时 | 存储 |
|-----|---------|---------|------|------|
| `-1` | 0 | 100 | ~1分钟 | 最小 |
| `50` | 50 | ~1100 | ~5分钟 | 适中 |
| `100` | 100 | ~2100 | ~10分钟 | 较大 |
| `0` | 100 | ~2100 | ~10分钟 | 最大 |

### GitHub API 限制

- **未认证**：60次/小时 ⚠️
- **认证用户**：5000次/小时 ✅
- **建议**：配置GitHub Token以提高限制

## 🎯 推荐配置

### 场景1：小型关键词（<30个仓库）
```
设置: 全部分析 (0)
原因: 数据量小，可以获取完整信息
```

### 场景2：中型关键词（30-100个仓库）
```
设置: 分析前100个 (默认)
原因: 平衡数据完整性和性能
```

### 场景3：大型关键词（>100个仓库）
```
设置: 分析前100个
原因: 前100个仓库通常是最有价值的（按星标排序）
```

### 场景4：只需仓库列表
```
设置: 不分析 (-1)
原因: 快速获取仓库元数据，不需要代码级别信息
```

## ⚡ 优化建议

1. **优先分析热门仓库**
   - 爬虫自动按星标排序
   - 前N个仓库通常是最有价值的

2. **配置多个GitHub Token**
   - 在 `.env` 中配置多个Token
   - 自动轮换使用，提高API限制

3. **分批处理**
   - 大型关键词可以多次爬取
   - 使用"重新爬取"功能补充数据

4. **按需分析**
   - 使用 `analyze_existing_repos.py` 脚本
   - 针对特定仓库进行补充分析

## 🔄 重新分析现有数据

如果修改了配置，可以重新分析已爬取的仓库：

```bash
# 分析geoip关键词的所有仓库
python backend/scraper/scripts/analyze_existing_repos.py geoip --limit 0

# 分析mmdb关键词的前30个仓库
python backend/scraper/scripts/analyze_existing_repos.py mmdb --limit 30
```

## 📝 注意事项

1. **全量分析风险**
   - 可能触发GitHub API限制
   - 爬取时间可能超过前端超时（10分钟）
   - 建议在服务器端单独运行

2. **数据完整性**
   - 即使设置为全部分析，部分仓库可能因权限问题无法访问
   - 私有仓库、空仓库会自动跳过

3. **性能权衡**
   - 分析越多，数据越完整，但时间越长
   - 建议根据实际需求选择合适的值

## 🆘 常见问题

### Q: 为什么我设置了0但还是没有全部分析？
A: 检查：
1. 前端设置是否正确保存
2. 是否重新触发了爬取
3. 查看爬虫日志确认配置

### Q: API限制怎么办？
A: 
1. 配置GitHub Token
2. 降低代码分析数量
3. 分多次爬取

### Q: 如何验证配置是否生效？
A: 查看爬虫日志，应该看到类似：
```
将分析所有 X 个仓库的代码（全量分析模式）
或
将分析 100/200 个仓库的代码（限制模式）
```

## 📚 相关文档

- [GitHub API 速率限制](https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting)
- [爬虫使用指南](./USER_GUIDE.md)
- [API文档](./API.md)


